<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns#">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


  <link href="../files/css/shCore.css" rel="stylesheet" type="text/css" />
  <link href="../files/css/shThemeDefault.css" rel="stylesheet" type="text/css" />

  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>ros-rvft: guidelines for developers and qa teams</title>
  <meta name="description" content="">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="generator" content="Hugo 0.57.2">
  <meta name="robots" content="index,follow">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta property="og:title" content="Verification of ROS-based Systems">
  <meta property="og:description" content="">
  <meta property="og:type" content="website">
  <meta property="og:url" content="-">
  <link rel="stylesheet" href="../files/styles.css">
  <link rel="stylesheet" href="../files/css">
  <link rel="stylesheet" href="../files/font-awesome.min.css"
    integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">




  <link href="-index.xml" rel="alternate" type="application/rss+xml">



  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

  <script id="MathJax-script" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_HTML"></script>

  <script id="MathJax-script" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_HTML">

      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          autoload: {
            color: [],
            colorv2: ['color']
          },
          displayMath: [['$$', '$$']],
          processEscapes: true,
          processEnvironments: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
          TeX: {
            equationNumbers: { autoNumber: "AMS" },
            extensions: ["AMSmath.js", "AMSsymbols.js"], packages: { '[+]': ['noerrors'] }
          }
        }
      });
      MathJax.Hub.Queue(function () {



        var all = MathJax.Hub.getAllJax(), i;
        for (i = 0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });

      MathJax.Hub.Config({
        TeX: { equationNumbers: { autoNumber: "AMS" } }

      });


      MathJax.Hub.Register.MessageHook("Math Processing Error", function (message) {
        //  do something with the error.  message[2] is the Error object that records the problem.
      });


    </script>


  <style>
    code.has-jax {
      font: inherit;
      font-size: 100%;
      background: inherit;
      border: inherit;
      color: #515151;
    }


    .patternformulae {
      display: block;
      margin-left: auto;
      margin-right: auto;
      padding: 70px;
      width: 90%;
    }
  </style>
  <style id="fit-vids-style">
    .fluid-width-video-wrapper {
      width: 100%;
      position: relative;
      padding: 0;
    }

    .fluid-width-video-wrapper iframe,
    .fluid-width-video-wrapper object,
    .fluid-width-video-wrapper embed {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
    }
  </style>
  <style type="text/css">
    .MathJax_Hover_Frame {
      border-radius: .25em;
      -webkit-border-radius: .25em;
      -moz-border-radius: .25em;
      -khtml-border-radius: .25em;
      box-shadow: 0px 0px 15px #83A;
      -webkit-box-shadow: 0px 0px 15px #83A;
      -moz-box-shadow: 0px 0px 15px #83A;
      -khtml-box-shadow: 0px 0px 15px #83A;
      border: 1px solid #A6D ! important;
      display: inline-block;
      position: absolute
    }
  </style>
</head>

<body>
  <div id="MathJax_Message" style="display: none;"></div>

  <script type="application/javascript">
    var doNotTrack = false;
    if (!doNotTrack) {
      (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
          (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date(); a = s.createElement(o),
          m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
      })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
      ga('create', 'UA-33213501-2', 'auto');

      ga('send', 'pageview');
    }
  </script>


  <header class="site-header">
    <nav class="navbar fixed-navbar">
        <ul class="site-nav">
	    <li class="site-nav-item"> <p>ROS-RVFT</p> </li>
            <li class="site-nav-item">
                <a title="Guideline Catalog" href="https://ros-rvft.github.io/index">Guideline Catalog</a>
            </li>
            <li class="site-nav-item">
                <a title="Replication package" href="https://ros-rvft.github.io/replication">Replication Package</a>
            </li>
            <li class="site-nav-item">
                <a title="Evaluation" href="https://ros-rvft.github.io/evaluation">Evaluation</a>
            </li>
            <li class="site-nav-item">
                <a title="Contribute" href="https://ros-rvft.github.io/contribute">Contribute</a>
            </li>
            <li class="site-nav-item">
                <a title="Authors" href="https://ros-rvft.github.io/authors">Authors</a>
            </li>
            <li class="site-nav-item">
                <a title="Research" href="https://ros-rvft.github.io/research">Cite Us!</a>
            </li>
        </ul>
    </nav>
</header>

  <!-- ---------------------------------- GUIDELINE HEADER ---------------------------------- -->
  <div class="container">
    <article class="post-container">
      <header class="post-header">
        <h1 class="post-title">PE1. Understand the overhead acceptance criteria</h1>
      </header>

      <div class="post-content clearfix">


        <h2 id="intent">Context (WHEN)</h2>

        <blockquote>
          <p>According to practitioners, performance is among the three most important quality attributes when designing a robotic application in ROS [1]. Performance is often important in robotics because many computations performed by robots tend to be data-intensive, e.g., computer vision, planning, and navigation [1]. Gaining confidence in robotic applications, then, should not interfere with the nominal performance of the robot under scrutiny. Less (or no) impact on performance is especially desirable when the assurance gathering process interacts with the running system, for instance, in-the-field testing and runtime verification. We name the extra load available for gaining confidence on ROSbased applications as overhead acceptance criteria. The overhead acceptance criteria can be allocated to monitoring, isolation, or maintaining the security of privacy during the runtime assessment session [2]. </p>
        </blockquote>



        <h2 id="relationships"> Reason (WHY)</h2>
        <p>A rule of thumb says that more observations tend to enable more precise assurance arguments within a limit. Observing, however, is never free from side effects, incurring in overhead [3]. Therefore, the quality assurance team must contrast the precision of the assurance arguments against overhead introduced by the observation medium. The overhead acceptance criteria are the basis for deciding the runtime assurance strategy.
        </p>

        <h2 id="occurences">Suggestion (WHAT)</h2>

        <p>The use of runtime
          verification or field-based techniques might add computation
          overhead. The QA team should understand how much
          overhead is acceptable; this is important to decide on a
          test strategy that will not severely impact the performance
          of the running system. Such overhead may be due to moni-
          toring with ros tracing (git: ros2/ros2 tracing), component
          isolation, or security and privacy maintenance overhead with
          ROSploit (git: seanrivera/rosploit).</p>


        <h2>Process (HOW)</h2>

        <p>
          Typically, understanding the overhead acceptance criteria follows from contrasting the required performance for delivering the required service, aka nominal performance (e.g., time to reaction, latency, speed), against available resources (e.g., computing power). The QA team may use off-the-shelf ROS tooling, like ApexAI/Performance <a href="https://gitlab.com/ApexAI/performance_test">ApexAI/Performance</a> test ß, to understand the nominal performance of the ROS-based application. The difference between nominal performance and expected performance may be allocated to the overhead acceptance criteria. If the nominal performance is close enough to the expected performance, there 1 is not enough space for implementing runtime assurance techniques. We categorise three types of overhead that may affect the runtime assurance process: Runtime Monitoring [4, 5], Isolation overhead [6, 7], and Security and Privacy overhead [8, 9]. 
        
        </p>



        <h2>Exemplars</h2>
        <h4 style="text-indent: 25px;">Monitoring overhead</h4>

        <p>

          Monitoring overhead is all extra load put on the system-under-test due to gathering, interpreting, and elaborating data about the execution. For example, ROSMonitoring <a href="https://github.com/autonomy-and-verification-uol/ROSMonitoring">autonomy-and-verification-uol/ROSMonitoring</a>[4] determines the monitoring overhead by calculating the delay introduced in the message delivery time between ROS nodes. The authors analyse the overhead by varying the size of the system under monitoring, message passing frequency, and number of monitor nodes. However, their overhead analysis is not transparent with respect to gathering, interpreting or elaborating on data, the analysis looks at the monitoring overhead as a black box.
        </p>

        <p>
          Another example is
          ros2 tracing
          <a href="https://github.com/ros2/ros2_tracing">(ros2/ros2 tracing)</a> [5]
          that provides a tool
          for tracing ROS2 systems with low latency overhead. The
          authors measure monitoring overhead by collecting the time
          between publishing a message and when it is handled by
          the subscription callback. In short, monitoring and tracing
          tools add some overhead that typically affects the message
          passing latency, the QA team must understand and define a
          precise time allowance to this overhead
        </p>

        <h4 style="text-indent: 25px;">Isolation overhead</h4>

        <p>
          Isolation overhead is all extra load put on the system-under-test for guaranteeing that the runtime assessment will not interfere with the normal operation or produce undesired side effects. As an example, Lahami M. et al. [6] propose a safe and resource-aware approach to test dynamic and distributed systems. Safe by employing testing isolation techniques such as BIT-based, tagging-based, aspect-based, cloning-based, and blocking-based. Resource aware by setting resource monitors such as processor load, main memory, and network bandwidth. The authors show that the overall overhead is relatively low and tolerable, mainly if dynamic adaptations are not commonly requested. However, there is no fine-grained evaluation of the overhead introduced by isolation techniques. In fact, isolation overhead is rarely reported [7]. 
        </p>

        <h4 style="text-indent: 25px;">Security and Privacy overhead</h4>

        <p>
          Security and Privacy overhead is all extra load put on the system-under-test for maintaining security and privacy constraints while testing. For example, ROS-Immunity is a security tool for preventing ROS-based applications from malicious attackers. Rivera S. et al. [8], determines overhead for maintaining the ROS-based system secure, while operating, in terms of power consumption (in Watts) by comparing the power draw of the system with and without their tool. From another stance, Breiling B. et al [9] present a secure communication channel to enable communication between ROS nodes using protocols such as Transport Layer Security (TLS) and Datagram Transport Layer Security (DTLS) per each ROS topic in the application. The protocols follow three steps: an initial handshake with mutual authentication, using symmetric encryption (AES-256), and using Message Authentication Codes (MAC) for data integrity. Importantly, 2 they evaluate the overhead introduced for each step, totalling in a few percentage points (2%-5%) of increase in average CPU load. 
        </p>

        <p class="strengths" style="text-indent: 25px;">Strengths:</p>
        <p> 
          Understanding the overhead ac-
          ceptance criteria in advance may avoid unexpected interrup-
          tions in the ROS application functionality due to runtime
          quality assessment procedures. For example, when testing
          procedures are mistakenly scheduled whenever the ROS-
          based application is operating under a high load. Learning
          about the overhead in advance criteria may also ask for
          re-design due to a lack of verifiability during runtime. For
          example, when the nominal performance of the ROS system
          is close to the expected performance, in value.
        </p>


        <p class="weaknesses" style="text-indent: 25px;">Weaknesses:</p>
        <p>
          Although there is tooling to
support the assessment of the overhead acceptance crite-
ria, the process for understanding involves executing the
system, collecting performance data and analysis. This may
conflict with time-to-market requirements, asking for further
negotiation with the business goals of the ROS-based system.
        </p>


        <p class="" style="text-indent: 25px;"> References </p> 
        <blockquote>

          <p>[1] I. Malavolta, G. A. Lewis et al., “Mining guidelines for architecting robotics software,” Journal of Systems and Software, vol. 178, p. 110969, 2021. </p>
          <p>[2] A. Bertolino, P. Braione et al., “A survey of field-based testing techniques,” ACM Computing Surveys (CSUR), vol. 54, no. 5, pp. 1–39, 2021. </p>
          <p>[3] Y. Falcone, S. Krsti´c et al., “A taxonomy for classifying runtime verification tools,” International Journal on Software Tools for Technology Transfer, vol. 23, no. 2, pp. 255–284, 2021. </p>
          <p>[4] A. Ferrando, R. C. Cardoso et al., “Rosmonitoring: a runtime verification framework for ros,” in Annual Conference Towards Autonomous Robotic Systems. Springer, 2020, pp. 387–399. </p>
          <p>[5] C. B´edard, P.-Y. Lajoie et al., “Message flow analysis with complex causal links for distributed ros 2 systems,” Robotics and Autonomous Systems, vol. 161, p. 104361, 2023. </p>
          <p>[6] M. Lahami, M. Krichen et al., “Safe and efficient runtime testing framework applied in dynamic and distributed systems,” Science of Computer Programming, vol. 122, pp. 1–28, 2016. </p>
          <p>[7] S. Silva, A. Bertolino et al., “Self-adaptive testing in the field: are we there yet?” in Proceedings of the 17th Symposium on Software Engineering for Adaptive and Self-Managing Systems, 2022, pp. 58–69.  </p>
          <p>[8] S. Rivera and R. State, “Securing robots: An integrated approach for security challenges and monitoring for the robotic operating system (ros),” in 2021 IFIP/IEEE International Symposium on Integrated Network Management (IM). IEEE, 2021, pp. 754–759. </p>
          <p>[9] B. Breiling, B. Dieber et al., “Secure communication for the robot operating system,” in 2017 annual IEEE international systems conference (SysCon). IEEE, 2017, pp. 1–6. </p>

        <blockquote>



          <!-- ---------------------------------- GUIDELINE CONTENT END ---------------------------------- -->


        </div>

      </div>

      <footer class="post-footer clearfix">


        <div class="share">




        </div>

  </div>
  <footer class="footer">
    <div class="container">
      <div class="site-title-wrapper">
        <h1 class="site-title">
                    <a title="ROS-RVFT: GUIDELINES FOR DEVELOPERS AND QA TEAMS" href="index.html">ROS-RVFT: GUIDELINES FOR DEVELOPERS AND QA TEAMS</a>
        </h1>

      </div>

      <p class="footer-copyright">
        <span>Ricardo Caldas, Juan Antonio Pinera Garcia, Matei Schiopu,
          Patrizio Pelliccione, Genaina Rodrigues, and Thorsten Berger © 2024 </span>
      </p>
      <p class="footer-copyright">


      </p>
    </div>
  </footer>

  <script src="../files/jquery-1.11.3.min.js.download"></script>
  <script src="../files/jquery.fitvids.js.download"></script>
  <script src="../files/highlight.min.js.download"></script>
  <script src="../files/scripts.js.download"></script>


</body>

</html>